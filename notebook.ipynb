{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wikipediaapi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwikipediaapi\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlparse, parse_qs\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wikipediaapi'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import wikipediaapi\n",
    "import json\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from typing import Type\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "class SearchToolArgsSchema(BaseModel):\n",
    "    query: str = Field(\n",
    "        description=\"The query you will search for.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# DuckDuckGo 검색 툴\n",
    "class CustomDDGSearchTool(BaseTool):\n",
    "    name = \"DDGSearchTool\"\n",
    "    description = \"\"\"\n",
    "    Use this tool to find documents using DuckDuckGo Search Engine.\n",
    "    It takes a query as an argument and fetches content from the resulting websites.\n",
    "    \"\"\"\n",
    "    args_schema: Type[SearchToolArgsSchema] = SearchToolArgsSchema\n",
    "\n",
    "    def _run(self, query: str):\n",
    "        try:\n",
    "            # DuckDuckGo 검색\n",
    "            search_url = f\"https://html.duckduckgo.com/html/?q={query}\"\n",
    "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "            response = requests.get(search_url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                results = soup.find_all('a', class_='result__a')\n",
    "                \n",
    "                # 각 웹사이트의 링크를 따라가서 콘텐츠 추출\n",
    "                extracted_content = []\n",
    "                print(len(results))\n",
    "                for result in results[:5]:\n",
    "                    url = result['href']\n",
    "                    actual_url = self.extract_actual_url(url)\n",
    "                    print(actual_url)\n",
    "                    if actual_url:\n",
    "                        website_content = self.fetch_website_content(actual_url)\n",
    "                        if website_content:\n",
    "                            extracted_content.append(website_content)\n",
    "                \n",
    "                all_content = \"\\n\\n\".join(extracted_content)\n",
    "                save_to_txt(f\"research_DDG.txt\", all_content)\n",
    "                return all_content\n",
    "            else:\n",
    "                return f\"Error fetching results from DuckDuckGo with status code {response.status_code}.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error fetching results from DuckDuckGo: {str(e)}\"\n",
    "\n",
    "    def extract_actual_url(self, duckduckgo_url: str):\n",
    "        \"\"\"DuckDuckGo 리다이렉션 URL에서 실제 URL을 추출하는 함수\"\"\"\n",
    "        parsed_url = urlparse(duckduckgo_url)\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        actual_url = query_params.get('uddg', [None])[0]\n",
    "        \n",
    "        # DuckDuckGo 리다이렉션 URL에 HTTPS 스킴이 없을 경우 추가\n",
    "        if actual_url and not actual_url.startswith('http'):\n",
    "            actual_url = 'https://' + actual_url\n",
    "        return actual_url\n",
    "\n",
    "    def fetch_website_content(self, url: str):\n",
    "        \"\"\"웹사이트의 콘텐츠를 가져오는 함수\"\"\"\n",
    "        try:\n",
    "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                paragraphs = soup.find_all('p')  # 주요 텍스트 콘텐츠 추출\n",
    "                return \"\\n\".join([p.get_text() for p in paragraphs])\n",
    "            else:\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            return f\"Error fetching content from {url}: {str(e)}\"\n",
    "\n",
    "\n",
    "class WikiPediaSearchTool(BaseTool):\n",
    "    name = \"WikiPediaSearchTool\"\n",
    "    description = \"\"\"\n",
    "    Use this tool to find the documents using Wikipedia.\n",
    "    It takes a query as an argument.\n",
    "    \"\"\"\n",
    "    args_schema: Type[SearchToolArgsSchema] = SearchToolArgsSchema\n",
    "\n",
    "    def _run(self, query: str):\n",
    "        try:\n",
    "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "            wiki_wiki = wikipediaapi.Wikipedia('en', headers=headers)  \n",
    "            page = wiki_wiki.page(query)\n",
    "            if page.exists():\n",
    "                save_to_txt(f\"research_WIKI.txt\", page.text)\n",
    "                return page.text\n",
    "            else:\n",
    "                return f\"No Wikipedia page found for {query}.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error fetching results from Wikipedia: {str(e)}\"\n",
    "\n",
    "\n",
    "agent = initialize_agent(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    handle_parsing_errors=True,\n",
    "    tools=[\n",
    "        CustomDDGSearchTool(),\n",
    "        WikiPediaSearchTool(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def save_to_txt(filename, content):\n",
    "    # content가 dict일 경우 JSON으로\n",
    "    if isinstance(content, dict):\n",
    "        content = json.dumps(content, indent=4, ensure_ascii=False)\n",
    "    with open(filename, 'a', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "\n",
    "query = \"XZ backdoor\"\n",
    "prompt = f\"Research about the {query}. You can use DuckDuckGoSearch Tool and WikipediaSearchTool.\"\n",
    "result = agent.invoke(prompt)\n",
    "\n",
    "save_to_txt(f\"research_{query}.txt\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai as client\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_G2BTRBBFDmC05QOpp06KvLsr', created_at=1726180036, description=None, instructions='You help users do research on query using by duckduckgo and wikipedia.', metadata={}, model='gpt-4o-mini', name='Research Assistant', object='assistant', tools=[FunctionTool(function=FunctionDefinition(name='get_docs_from_dgg', description='Given the query returns its related documents using by duckduckgosearch engine.', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Something I want to know'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='get_docs_from_wiki', description='Given the query returns its related documents using by wikipedia dictionary.', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Something I want to know'}}, 'required': ['query']}, strict=False), type='function')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_docs_from_dgg\",\n",
    "            \"description\": \"Given the query returns its related documents using by duckduckgosearch engine.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Something I want to know\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_docs_from_wiki\",\n",
    "            \"description\": \"Given the query returns its related documents using by wikipedia dictionary.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Something I want to know\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Research Assistant\",\n",
    "    instructions=\"You help users do research on query using by duckduckgo and wikipedia.\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=functions,\n",
    ")\n",
    "\n",
    "assistant\n",
    "\n",
    "\n",
    "# assistant_id = \"asst_G2BTRBBFDmC05QOpp06KvLsr\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
